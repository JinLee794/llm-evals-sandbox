{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate AI agents (Azure AI Agent Service) in Azure AI Foundry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "\n",
    "This sample demonstrates how to evaluate an AI agent (Azure AI Agent Service) on these important aspects of your agentic workflow:\n",
    "\n",
    "- Intent Resolution: Measures how well the agent identifies the user’s request, including how well it scopes the user’s intent, asks clarifying questions, and reminds end users of its scope of capabilities.\n",
    "- Tool Call Accuracy: Evaluates the agent's ability to select the appropriate tools, and process correct parameters from previous steps.\n",
    "- Task Adherence: Measures how well the agent’s response adheres to its assigned tasks, according to its system message and prior steps.\n",
    "\n",
    "For AI agents outside of Azure AI Agent Service, you can still provide th agent data in the two formats (either simple data or agent messages) specified in the individual evaluator samples:\n",
    "- [Intent resolution](https://aka.ms/intentresolution-sample)\n",
    "- [Tool call accuracy](https://aka.ms/toolcallaccuracy-sample)\n",
    "- [Task adherence](https://aka.ms/taskadherence-sample)\n",
    "- [Response Completeness](https://aka.ms/rescompleteness-sample)\n",
    "\n",
    "\n",
    "\n",
    "## Time \n",
    "\n",
    "You should expect to spend about 20 minutes running this notebook. \n",
    "\n",
    "## Before you begin\n",
    "Creating an agent using Azure AI agent service requires an Azure AI Foundry project and a deployed, supported model. See more details in [Create a new agent](https://learn.microsoft.com/azure/ai-services/agents/quickstart?pivots=ai-foundry-portal).\n",
    "\n",
    "For quality evaluation, you need to deploy a `gpt` model supporting JSON mode. We recommend a model `gpt-4o` or `gpt-4o-mini` for their strong reasoning capabilities.    \n",
    "\n",
    "Important: Make sure to authenticate to Azure using `az login` in your terminal before running this notebook.\n",
    "\n",
    "### Prerequisite\n",
    "\n",
    "Before running the sample:\n",
    "```bash\n",
    "pip install azure-ai-projects azure-identity azure-ai-evaluation\n",
    "```\n",
    "Set these environment variables with your own values:\n",
    "1) **PROJECT_CONNECTION_STRING** - The project connection string, as found in the overview page of your Azure AI Foundry project.\n",
    "2) **MODEL_DEPLOYMENT_NAME** - The deployment name of the model for AI-assisted evaluators, as found under the \"Name\" column in the \"Models + endpoints\" tab in your Azure AI Foundry project.\n",
    "3) **AZURE_OPENAI_ENDPOINT** - Azure Open AI Endpoint to be used for evaluation.\n",
    "4) **AZURE_OPENAI_API_KEY** - Azure Open AI Key to be used for evaluation.\n",
    "5) **AZURE_OPENAI_API_VERSION** - Azure Open AI Api version to be used for evaluation.\n",
    "6) **AZURE_SUBSCRIPTION_ID** - Azure Subscription Id of Azure AI Project\n",
    "7) **PROJECT_NAME** - Azure AI Project Name\n",
    "8) **RESOURCE_GROUP_NAME** - Azure AI Project Resource Group Name\n",
    "9) **AGENT_MODEL_DEPLOYMENT_NAME** - The deployment name of the model for your Azure AI agent, as found under the \"Name\" column in the \"Models + endpoints\" tab in your Azure AI Foundry project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Project Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import FunctionTool, ToolSet\n",
    "\n",
    "# Import your custom functions to be used as Tools for the Agent\n",
    "from user_functions import user_functions\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_FOUNDRY_ENDPOINT\"],\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "AGENT_NAME = \"Seattle Tourist Assistant\"\n",
    "\n",
    "# Add Tools to be used by Agent\n",
    "functions = FunctionTool(user_functions)\n",
    "\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)\n",
    "\n",
    "# To enable tool calls executed automatically\n",
    "project_client.agents.enable_auto_function_calls(tools=toolset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an AI agent (Azure AI Agent Service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, ID: asst_mc3diJKGt4pjMKZq8IgQnSxb\n"
     ]
    }
   ],
   "source": [
    "agent = project_client.agents.create_agent(\n",
    "    model=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    name=AGENT_NAME,\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    toolset=toolset,\n",
    ")\n",
    "\n",
    "print(f\"Created agent, ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, ID: thread_1n3TpNNjoXYjvNEJO7i4HswG\n",
      "{'id': 'run_yMCCUKyavbsLWcm96b7JcWNo', 'object': 'thread.run', 'created_at': 1756162418, 'assistant_id': 'asst_mc3diJKGt4pjMKZq8IgQnSxb', 'thread_id': 'thread_1n3TpNNjoXYjvNEJO7i4HswG', 'status': 'in_progress', 'started_at': 1756162418, 'expires_at': 1756164218, 'cancelled_at': None, 'failed_at': None, 'completed_at': None, 'required_action': None, 'last_error': None, 'model': 'gpt-4.1', 'instructions': 'You are a helpful assistant', 'tools': [{'type': 'function', 'function': {'name': 'opening_hours', 'description': 'Fetches the opening hours of a tourist destination in Seattle.', 'parameters': {'type': 'object', 'properties': {'tourist_destination': {'type': 'string', 'description': 'The tourist destination to fetch opening hours for.'}}, 'required': ['tourist_destination']}, 'strict': False}}, {'type': 'function', 'function': {'name': 'get_user_info', 'description': 'Retrieves user information based on user ID.', 'parameters': {'type': 'object', 'properties': {'user_id': {'type': 'integer', 'description': 'ID of the user.'}}, 'required': ['user_id']}, 'strict': False}}, {'type': 'function', 'function': {'name': 'convert_temperature', 'description': 'Converts temperature from Celsius to Fahrenheit.', 'parameters': {'type': 'object', 'properties': {'celsius': {'type': 'number', 'description': 'Temperature in Celsius.'}}, 'required': ['celsius']}, 'strict': False}}, {'type': 'function', 'function': {'name': 'send_email', 'description': 'Sends an email with the specified subject and body to the recipient.', 'parameters': {'type': 'object', 'properties': {'recipient': {'type': 'string', 'description': 'Email address of the recipient.'}, 'subject': {'type': 'string', 'description': 'Subject of the email.'}, 'body': {'type': 'string', 'description': 'Body content of the email.'}}, 'required': ['recipient', 'subject', 'body']}, 'strict': False}}, {'type': 'function', 'function': {'name': 'longest_word_in_sentences', 'description': 'Finds the longest word in each sentence.', 'parameters': {'type': 'object', 'properties': {'sentences': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of sentences.'}}, 'required': ['sentences']}, 'strict': False}}, {'type': 'function', 'function': {'name': 'toggle_flag', 'description': 'Toggles a boolean flag.', 'parameters': {'type': 'object', 'properties': {'flag': {'type': 'boolean', 'description': 'The flag to toggle.'}}, 'required': ['flag']}, 'strict': False}}, {'type': 'function', 'function': {'name': 'fetch_weather', 'description': 'Fetches the weather information for the specified location.', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The location to fetch weather for.'}}, 'required': ['location']}, 'strict': False}}, {'type': 'function', 'function': {'name': 'fetch_current_datetime', 'description': 'Get the current time as a JSON string, optionally formatted.', 'parameters': {'type': 'object', 'properties': {'format': {'type': ['string', 'null'], 'description': 'The format in which to return the current time. Defaults to None, which uses a standard format.'}}, 'required': []}, 'strict': False}}, {'type': 'function', 'function': {'name': 'process_records', 'description': 'Process a list of records, where each record is a dictionary with string keys and integer values.', 'parameters': {'type': 'object', 'properties': {'records': {'type': 'array', 'items': {'type': 'object'}, 'description': 'A list containing dictionaries that map strings to integers.'}}, 'required': ['records']}, 'strict': False}}, {'type': 'function', 'function': {'name': 'merge_dicts', 'description': 'Merges two dictionaries.', 'parameters': {'type': 'object', 'properties': {'dict1': {'type': 'object', 'description': 'First dictionary.'}, 'dict2': {'type': 'object', 'description': 'Second dictionary.'}}, 'required': ['dict1', 'dict2']}, 'strict': False}}, {'type': 'function', 'function': {'name': 'calculate_sum', 'description': 'Calculates the sum of two integers.', 'parameters': {'type': 'object', 'properties': {'a': {'type': 'integer', 'description': 'First integer.'}, 'b': {'type': 'integer', 'description': 'Second integer.'}}, 'required': ['a', 'b']}, 'strict': False}}], 'tool_resources': {}, 'metadata': {}, 'temperature': 1.0, 'top_p': 1.0, 'max_completion_tokens': None, 'max_prompt_tokens': None, 'truncation_strategy': {'type': 'auto', 'last_messages': None}, 'incomplete_details': None, 'usage': None, 'response_format': 'auto', 'tool_choice': 'auto', 'parallel_tool_calls': True}\n"
     ]
    }
   ],
   "source": [
    "thread = project_client.agents.create_thread_and_run(agent_id=agent.id)\n",
    "print(f\"Created thread, ID: {thread.thread_id}\")\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation with Agent\n",
    "Use below cells to have conversation with the agent\n",
    "- `Create Message[1]`\n",
    "- `Execute[2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Message[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message, ID: msg_ilKefi1WWqvPF81bLRy8afHG\n"
     ]
    }
   ],
   "source": [
    "# Create message to thread\n",
    "\n",
    "MESSAGE = \"Can you email me weather info for Seattle ?\"\n",
    "\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.thread_id,\n",
    "    role=\"user\",\n",
    "    content=MESSAGE,\n",
    ")\n",
    "print(f\"Created message, ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished with status: RunStatus.COMPLETED\n",
      "Run ID: run_9wClwjmDueaEJtyMdpbzQi6n\n"
     ]
    }
   ],
   "source": [
    "run = project_client.agents.create_thread_and_process_run(agent_id=agent.id)\n",
    "\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "print(f\"Run ID: {run.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: MessageRole.AGENT\n",
      "Content: Hi! How can I assist you today?\n",
      "----------------------------------------\n",
      "Role: MessageRole.USER\n",
      "Content: Can you email me weather info for Seattle ?\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for message in project_client.agents.messages.list(thread_id=thread.thread_id, order=\"asc\"):\n",
    "    print(f\"Role: {message.role}\")\n",
    "    print(f\"Content: {message.content[0].text.value}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data from agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AIAgentConverter: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class FDPAgentDataRetriever: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AIAgentDataRetriever: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"query\": [\n",
      "            {\n",
      "                \"role\": \"system\",\n",
      "                \"content\": \"You are a helpful assistant\"\n",
      "            }\n",
      "        ],\n",
      "        \"response\": [\n",
      "            {\n",
      "                \"createdAt\": \"2025-08-25T22:53:52Z\",\n",
      "                \"run_id\": \"run_9wClwjmDueaEJtyMdpbzQi6n\",\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": [\n",
      "                    {\n",
      "                        \"type\": \"text\",\n",
      "                        \"text\": \"Hello! How can I assist you today?\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"tool_definitions\": [\n",
      "            {\n",
      "                \"name\": \"opening_hours\",\n",
      "                \"type\": \"function\",\n",
      "                \"description\": \"Fetches the opening hours of a tourist destination in Seattle.\",\n",
      "                \"parameters\": {\n",
      "                    \"type\": \"object\",\n",
      "                    \"properties\": {\n",
      "                        \"tourist_destination\": {\n",
      "                            \"type\": \"string\",\n",
      "                            \"description\": \"The tourist destination to fetch opening hours for.\"\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"get_user_info\",\n",
      "                \"type\": \"function\",\n",
      "                \"description\": \"Retrieves user information based on user ID.\",\n",
      "                \"parameters\": {\n",
      "                    \"type\": \"object\",\n",
      "                    \"properties\": {\n",
      "                        \"user_id\": {\n",
      "                            \"type\": \"integer\",\n",
      "                            \"description\": \"ID of the user.\"\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"convert_temperature\",\n",
      "                \"type\": \"function\",\n",
      "                \"description\": \"Converts temperature from Celsius to Fahrenheit.\",\n",
      "                \"parameters\": {\n",
      "                    \"type\": \"object\",\n",
      "                    \"properties\": {\n",
      "                        \"celsius\": {\n",
      "                            \"type\": \"number\",\n",
      "                            \"description\": \"Temperature in Celsius.\"\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"send_email\",\n",
      "                \"type\": \"function\",\n",
      "                \"description\": \"Sends an email with the specified subject and body to the recipient.\",\n",
      "                \"parameters\": {\n",
      "                    \"type\": \"object\",\n",
      "                    \"properties\": {\n",
      "                        \"recipient\": {\n",
      "                            \"type\": \"string\",\n",
      "                            \"description\": \"Email address of the recipient.\"\n",
      "                        },\n",
      "                        \"subject\": {\n",
      "                            \"type\": \"string\",\n",
      "                            \"description\": \"Subject of the email.\"\n",
      "                        },\n",
      "                        \"body\": {\n",
      "                            \"type\": \"string\",\n",
      "                            \"description\": \"Body content of the email.\"\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"longest_word_in_sentences\",\n",
      "                \"type\": \"function\",\n",
      "                \"description\": \"Finds the longest word in each sentence.\",\n",
      "                \"parameters\": {\n",
      "                    \"type\": \"object\",\n",
      "                    \"properties\": {\n",
      "                        \"sentences\": {\n",
      "                            \"type\": \"array\",\n",
      "                            \"items\": {\n",
      "                                \"type\": \"string\"\n",
      "                            },\n",
      "                            \"description\": \"A list of sentences.\"\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"toggle_flag\",\n",
      "                \"type\": \"function\",\n",
      "                \"description\": \"Toggles a boolean flag.\",\n",
      "                \"parameters\": {\n",
      "                    \"type\": \"object\",\n",
      "                    \"properties\": {\n",
      "                        \"flag\": {\n",
      "                            \"type\": \"boolean\",\n",
      "                            \"description\": \"The flag to toggle.\"\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"fetch_weather\",\n",
      "                \"type\": \"function\",\n",
      "                \"description\": \"Fetches the weather information for the specified location.\",\n",
      "                \"parameters\": {\n",
      "                    \"type\": \"object\",\n",
      "                    \"properties\": {\n",
      "                        \"location\": {\n",
      "                            \"type\": \"string\",\n",
      "                            \"description\": \"The location to fetch weather for.\"\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"fetch_current_datetime\",\n",
      "                \"type\": \"function\",\n",
      "                \"description\": \"Get the current time as a JSON string, optionally formatted.\",\n",
      "                \"parameters\": {\n",
      "                    \"type\": \"object\",\n",
      "                    \"properties\": {\n",
      "                        \"format\": {\n",
      "                            \"type\": [\n",
      "                                \"string\",\n",
      "                                \"null\"\n",
      "                            ],\n",
      "                            \"description\": \"The format in which to return the current time. Defaults to None, which uses a standard format.\"\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"process_records\",\n",
      "                \"type\": \"function\",\n",
      "                \"description\": \"Process a list of records, where each record is a dictionary with string keys and integer values.\",\n",
      "                \"parameters\": {\n",
      "                    \"type\": \"object\",\n",
      "                    \"properties\": {\n",
      "                        \"records\": {\n",
      "                            \"type\": \"array\",\n",
      "                            \"items\": {\n",
      "                                \"type\": \"object\"\n",
      "                            },\n",
      "                            \"description\": \"A list containing dictionaries that map strings to integers.\"\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"merge_dicts\",\n",
      "                \"type\": \"function\",\n",
      "                \"description\": \"Merges two dictionaries.\",\n",
      "                \"parameters\": {\n",
      "                    \"type\": \"object\",\n",
      "                    \"properties\": {\n",
      "                        \"dict1\": {\n",
      "                            \"type\": \"object\",\n",
      "                            \"description\": \"First dictionary.\"\n",
      "                        },\n",
      "                        \"dict2\": {\n",
      "                            \"type\": \"object\",\n",
      "                            \"description\": \"Second dictionary.\"\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"calculate_sum\",\n",
      "                \"type\": \"function\",\n",
      "                \"description\": \"Calculates the sum of two integers.\",\n",
      "                \"parameters\": {\n",
      "                    \"type\": \"object\",\n",
      "                    \"properties\": {\n",
      "                        \"a\": {\n",
      "                            \"type\": \"integer\",\n",
      "                            \"description\": \"First integer.\"\n",
      "                        },\n",
      "                        \"b\": {\n",
      "                            \"type\": \"integer\",\n",
      "                            \"description\": \"Second integer.\"\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import AIAgentConverter\n",
    "\n",
    "# Initialize the converter that will be backed by the project.\n",
    "converter = AIAgentConverter(project_client)\n",
    "\n",
    "# Use the thread id associated with the run to ensure the run and thread match.\n",
    "# Fallback to the previously created thread if the run does not have an associated thread id.\n",
    "thread_id = run.thread_id if getattr(run, \"thread_id\", None) else thread.thread_id\n",
    "run_id = run.id\n",
    "file_name = \"evaluation_data.jsonl\"\n",
    "\n",
    "# Get a single agent run data\n",
    "evaluation_data_single_run = converter.convert(thread_id=thread_id, run_id=run_id)\n",
    "\n",
    "# Run this to save thread data to a JSONL file for evaluation\n",
    "# Save the agent thread data to a JSONL file\n",
    "import json\n",
    "evaluation_data = converter.prepare_evaluation_data(thread_ids=thread_id, filename=file_name)\n",
    "print(json.dumps(evaluation_data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up evaluator\n",
    "\n",
    "We will select the following evaluators to assess the different aspects relevant for agent quality: \n",
    "\n",
    "- [Intent resolution](https://aka.ms/intentresolution-sample): measures the extent of which an agent identifies the correct intent from a user query. Scale: integer 1-5. Higher is better.\n",
    "- [Tool call accuracy](https://aka.ms/toolcallaccuracy-sample): evaluates the agent’s ability to select the appropriate tools, and process correct parameters from previous steps. Scale: float 0-1. Higher is better.\n",
    "- [Task adherence](https://aka.ms/taskadherence-sample): measures the extent of which an agent’s final response adheres to the task based on its system message and a user query. Scale: integer 1-5. Higher is better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class IntentResolutionEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ToolCallAccuracyEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class TaskAdherenceEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import (\n",
    "    ToolCallAccuracyEvaluator,\n",
    "    AzureOpenAIModelConfiguration,\n",
    "    IntentResolutionEvaluator,\n",
    "    TaskAdherenceEvaluator,\n",
    ")\n",
    "from pprint import pprint\n",
    "\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    ")\n",
    "# Needed to use content safety evaluators\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ[\"AZURE_SUBSCRIPTION_ID\"],\n",
    "    \"project_name\": os.environ[\"AZURE_AI_FOUNDRY_PROJECT_NAME\"],\n",
    "    \"resource_group_name\": os.environ[\"AZURE_RESOURCE_GROUP_NAME\"],\n",
    "}\n",
    "\n",
    "intent_resolution = IntentResolutionEvaluator(model_config=model_config)\n",
    "\n",
    "tool_call_accuracy = ToolCallAccuracyEvaluator(model_config=model_config)\n",
    "\n",
    "task_adherence = TaskAdherenceEvaluator(model_config=model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "EvaluationException",
     "evalue": "(InternalError) The get 'aifoundry825233136833' workspace request failed with HTTP 404 - (ResourceNotFound) The Resource 'Microsoft.MachineLearningServices/workspaces/aifoundry825233136833' under resource group 'AIFoundry' was not found. For more details please go to https://aka.ms/ARMResourceNotFoundFix",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEvaluationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazure\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluate, AzureAIProject\n\u001b[32m      3\u001b[39m proj = AzureAIProject(\n\u001b[32m      4\u001b[39m     subscription_id=os.environ[\u001b[33m\"\u001b[39m\u001b[33mAZURE_SUBSCRIPTION_ID\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      5\u001b[39m     resource_group_name=os.environ[\u001b[33m\"\u001b[39m\u001b[33mAZURE_RESOURCE_GROUP_NAME\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      6\u001b[39m     project_name=os.environ[\u001b[33m\"\u001b[39m\u001b[33mAZURE_AI_FOUNDRY_PROJECT_NAME\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m response = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_call_accuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_accuracy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mintent_resolution\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mintent_resolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtask_adherence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_adherence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mazure_ai_project\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./evaluation_results.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m pprint(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAI Foundary URL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.get(\u001b[33m\"\u001b[39m\u001b[33mstudio_url\u001b[39m\u001b[33m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/_Demos/llm-evaluations-workshop/llm-evals-workshop/lib/python3.11/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:829\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(data, evaluators, evaluation_name, target, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EvaluationException):\n\u001b[32m    822\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EvaluationException(\n\u001b[32m    823\u001b[39m         message=\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    824\u001b[39m         target=ErrorTarget.EVALUATE,\n\u001b[32m    825\u001b[39m         category=ErrorCategory.FAILED_EXECUTION,\n\u001b[32m    826\u001b[39m         blame=ErrorBlame.SYSTEM_ERROR,\n\u001b[32m    827\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/_Demos/llm-evaluations-workshop/llm-evals-workshop/lib/python3.11/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:787\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(data, evaluators, evaluation_name, target, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, **kwargs)\u001b[39m\n\u001b[32m    785\u001b[39m     user_agent: Optional[\u001b[38;5;28mstr\u001b[39m] = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33muser_agent\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    786\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m UserAgentSingleton().add_useragent_product(user_agent) \u001b[38;5;28;01mif\u001b[39;00m user_agent \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext():\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m            \u001b[49m\u001b[43mevaluation_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m            \u001b[49m\u001b[43mevaluators_and_graders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m            \u001b[49m\u001b[43mevaluator_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m            \u001b[49m\u001b[43mazure_ai_project\u001b[49m\u001b[43m=\u001b[49m\u001b[43mazure_ai_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfail_on_evaluator_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfail_on_evaluator_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    799\u001b[39m     \u001b[38;5;66;03m# Handle multiprocess bootstrap error\u001b[39;00m\n\u001b[32m    800\u001b[39m     bootstrap_error = (\n\u001b[32m    801\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn attempt has been made to start a new process before the\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m        \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    802\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcurrent process has finished its bootstrapping phase.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    803\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/_Demos/llm-evaluations-workshop/llm-evals-workshop/lib/python3.11/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:966\u001b[39m, in \u001b[36m_evaluate\u001b[39m\u001b[34m(evaluators_and_graders, evaluation_name, target, data, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, **kwargs)\u001b[39m\n\u001b[32m    964\u001b[39m     studio_url = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    965\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trace_destination:\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m         studio_url = \u001b[43m_log_metrics_and_instance_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_destination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m result_df_dict = results_df.to_dict(\u001b[33m\"\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    971\u001b[39m result: EvaluationResult = {\u001b[33m\"\u001b[39m\u001b[33mrows\u001b[39m\u001b[33m\"\u001b[39m: result_df_dict, \u001b[33m\"\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m\"\u001b[39m: metrics, \u001b[33m\"\u001b[39m\u001b[33mstudio_url\u001b[39m\u001b[33m\"\u001b[39m: studio_url}  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/_Demos/llm-evaluations-workshop/llm-evals-workshop/lib/python3.11/site-packages/azure/ai/evaluation/_evaluate/_utils.py:234\u001b[39m, in \u001b[36m_log_metrics_and_instance_results\u001b[39m\u001b[34m(metrics, instance_results, trace_destination, run, evaluation_name, name_map, **kwargs)\u001b[39m\n\u001b[32m    226\u001b[39m ws_triad = extract_workspace_triad_from_trace_provider(trace_destination)\n\u001b[32m    227\u001b[39m management_client = LiteMLClient(\n\u001b[32m    228\u001b[39m     subscription_id=ws_triad.subscription_id,\n\u001b[32m    229\u001b[39m     resource_group=ws_triad.resource_group_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    232\u001b[39m     \u001b[38;5;66;03m# let the client automatically determine the credentials to use\u001b[39;00m\n\u001b[32m    233\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m tracking_uri = \u001b[43mmanagement_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mworkspace_get_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mws_triad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[43m)\u001b[49m.ml_flow_tracking_uri\n\u001b[32m    236\u001b[39m \u001b[38;5;66;03m# Adding line_number as index column this is needed by UI to form link to individual instance run\u001b[39;00m\n\u001b[32m    237\u001b[39m instance_results[\u001b[33m\"\u001b[39m\u001b[33mline_number\u001b[39m\u001b[33m\"\u001b[39m] = instance_results.index.values\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/_Demos/llm-evaluations-workshop/llm-evals-workshop/lib/python3.11/site-packages/azure/ai/evaluation/_azure/_clients.py:159\u001b[39m, in \u001b[36mLiteMLClient.workspace_get_info\u001b[39m\u001b[34m(self, workspace_name)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mworkspace_get_info\u001b[39m(\u001b[38;5;28mself\u001b[39m, workspace_name: \u001b[38;5;28mstr\u001b[39m) -> Workspace:\n\u001b[32m    151\u001b[39m     \u001b[38;5;66;03m# https://learn.microsoft.com/rest/api/azureml/workspaces/get?view=rest-azureml-2024-10-01\u001b[39;00m\n\u001b[32m    152\u001b[39m     workspace_response = \u001b[38;5;28mself\u001b[39m._http_client.request(\n\u001b[32m    153\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGET\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    154\u001b[39m         \u001b[38;5;28mself\u001b[39m._generate_path(*PATH_ML_WORKSPACES, workspace_name),\n\u001b[32m    155\u001b[39m         params={QUERY_KEY_API_VERSION: \u001b[38;5;28mself\u001b[39m._api_version},\n\u001b[32m    156\u001b[39m         headers=\u001b[38;5;28mself\u001b[39m._get_headers(),\n\u001b[32m    157\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_throw_on_http_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkspace_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mworkspace_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m workspace\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m     workspace = Workspace.deserialize(workspace_response)\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m workspace\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/_Demos/llm-evaluations-workshop/llm-evals-workshop/lib/python3.11/site-packages/azure/ai/evaluation/_azure/_clients.py:191\u001b[39m, in \u001b[36mLiteMLClient._throw_on_http_error\u001b[39m\u001b[34m(response, description, valid_status)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (JSONDecodeError, \u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m EvaluationException(\n\u001b[32m    192\u001b[39m     message=message,\n\u001b[32m    193\u001b[39m     target=ErrorTarget.EVALUATE,\n\u001b[32m    194\u001b[39m     category=ErrorCategory.FAILED_EXECUTION,\n\u001b[32m    195\u001b[39m     blame=ErrorBlame.SYSTEM_ERROR,\n\u001b[32m    196\u001b[39m )\n",
      "\u001b[31mEvaluationException\u001b[39m: (InternalError) The get 'aifoundry825233136833' workspace request failed with HTTP 404 - (ResourceNotFound) The Resource 'Microsoft.MachineLearningServices/workspaces/aifoundry825233136833' under resource group 'AIFoundry' was not found. For more details please go to https://aka.ms/ARMResourceNotFoundFix"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import evaluate, AzureAIProject\n",
    "\n",
    "proj = AzureAIProject(\n",
    "    subscription_id=os.environ[\"AZURE_SUBSCRIPTION_ID\"],\n",
    "    resource_group_name=os.environ[\"AZURE_RESOURCE_GROUP_NAME\"],\n",
    "    project_name=os.environ[\"AZURE_AI_FOUNDRY_PROJECT_NAME\"],\n",
    ")\n",
    "\n",
    "response = evaluate(\n",
    "    data=file_name,\n",
    "    evaluators={\n",
    "        \"tool_call_accuracy\": tool_call_accuracy,\n",
    "        \"intent_resolution\": intent_resolution,\n",
    "        \"task_adherence\": task_adherence,\n",
    "    },\n",
    "    azure_ai_project=proj,\n",
    "    output_path=\"./evaluation_results.json\"\n",
    "\n",
    ")\n",
    "pprint(f'AI Foundary URL: {response.get(\"studio_url\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect results on Azure AI Foundry\n",
    "\n",
    "Go to AI Foundry URL for rich Azure AI Foundry data visualization to inspect the evaluation scores and reasoning to quickly identify bugs and issues of your agent to fix and improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pprint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# alternatively, you can use the following to get the evaluation results in memory\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# average scores across all runs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mpprint\u001b[49m(response[\u001b[33m\"\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'pprint' is not defined"
     ]
    }
   ],
   "source": [
    "# alternatively, you can use the following to get the evaluation results in memory\n",
    "\n",
    "# average scores across all runs\n",
    "pprint(response[\"metrics\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-evals-workshop (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
